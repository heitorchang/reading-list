p. 45-46 Given the set of functions Big-Theta(g(n)), g(n) is an asymptotically tight bound for any f(n) belonging to this set.

f(n) belongs to Big-Theta(g(n)) if there exist positive constants c1, c2, and n0 such that 0 <= c1*g(n) <= f(n) <= c2*g(n) for all n >= n0

p. 47 Big-O notation is only an asymptotic upper bound. O(g(n)) is a set of functions such that

O(g(n)) = {f(n): there exist positive constants c and n0 such that 0 <= f(n) <= c*g(n) for all n >= n0}

p. 52 an analogy between asymptotic comparison of functions f and g and real numbers is:

f(n) = O(g(n))     is like a <= b (tight bound)
f(n) = Omega(g(n)) is like a >= b (tight bound)
f(n) = Theta(g(n)) is like a = b
f(n) = o(g(n))     is like a < b
f(n) = omega(g(n)) is like a > b

p. 147 In sorting problems, the numbers to be sorted are keys of records. The records are part of the collection of data to be sorted. In addition to the key, each record typically contains "satellite data."

p. 162 A max-priority queue may be used to schedule jobs (higher priority items get performed first). A min-priority queue may simulate events according to each event's time of occurrence.

p. 215 In the problem of finding the min and max elements of an array, process the elements in pairs, say a and b. First compare a with b, then compare the smaller of the two with the current minimum, and the larger with the current maximum. Thus we need 3 comparisons per 2 elements instead of 2 comparisons per 1 element, as would be done in a more obvious way.

p. 359 "Programming" in dynamic programming refers to a tabular method, not to writing computer code.

p. 362 The rod-cutting problem (to maximize the revenue of selling pieces of a rod) exhibits optimal substructure: optimal solutions incorporate optimal solutions to related subproblems, which may be solved independently.

Alternatively, an optimal solution can be defined recursively as the decomposition of a left-hand piece and a right-hand piece, and only the right piece can be further divided.

p. 372 Applying dynamic programming (in the problem of optimally parenthesizing a matrix chain)

1. Characterize the structure of an optimal solution
2. Recursively define the value of an optimal solution
3. Compute the value of an optimal solution
4. Construct an optimal solution from computed information

p. 379 The "cut-and-paste" argument that solutions to subproblems must be optimal: by "cutting out" the nonoptimal solution and "pasting in" the optimal one, you show that you can get a better solution to the original problem, thus contradicting your supposition that you already had an optimal solution.

p. 389 In general, a bottom-up dynamic-programming algorithm outperforms the corresponding top-down memoized algorithm by a constant factor because there is no overhead for recursion and table maintenance. However, if some subproblems do not need to be solved at all, the top-down memoized solution might be better (it will only solve subproblems that are definitely required).

