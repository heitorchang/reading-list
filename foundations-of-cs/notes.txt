p. 2

Example of exam scheduling without conflicts: a course-conflict graph with edges representing at least one student taking both courses

p. 3

Definitions of data models, data structures, and algorithms.

Data model: abstraction used to describe problems
Data structure: programming language constructs used to represent data models
Algorithm: technique used to obtain solutions by manipulating data

p. 7

The list data model in C

p. 14

The static part of the C data model: the type system

Union types

p. 15

Pointer types

p. 17

typedef

p. 28

Self-definition, basis-induction, "basis" case, and "inductive" case

p. 29-31

Selection sort

p. 34-35

Inductive Proofs (weak induction)

p. 36

Why proofs by induction work? Technically, induction must be accepted as axiomatic.

First informal proof: Iteration of the inductive step
Second informal proof: Least counterexample (minimal counterexample):
  Suppose S(n) is false for some value a, the least nonnegative integer for which S(a) is false.
  If a = 0, we contradict the basis, S(0), so a must be greater than 0.
  Now, if S(a) is false, S(a-1) is true (because a is the least nonnegative integer where S(a) is false).
  Replacing n with a-1 in the inductive step, S(a-1) implies S(a). Since S(a-1) is true, S(a) must be true: another contradiction.
  Because of these contradictions, S(n) must be true for any n >= 0
  
  (what if a = 1?) We showed how the inductive step holds, so S(a) cannot be false.

p. 38

Error-detecting codes

p. 43

Formulas for sums of arithmetic and geometric series

p. 44

Template for simple (weak) inductions

p. 45

Complete (also called strong or perfect) induction: entitlement to use S(i) for all values of i from the basis value up to n.

1. Prove the basis, S(0)
2. As an inductive hypothesis, assume S(0), S(1), ..., S(n) to be true. With these statements, prove that S(n+1) holds.

p. 46

Justifying complete induction (with a "least counterexample" argument)

p. 47

Associativity and commutativity

p. 51

A template for all inductions

1. Specify the statement S(n) to be proved. Say you are going to prove S(n) by induction on n. Explain what n represents.

2. State the basis case(s). These will be the integers i0 ... j0

3. Prove each of the basis cases S(i0), S(i0 + 1), ..., S(j0).

4. Set up the inductive step by stating that you are assuming S(i0), S(i0 + 1), ..., S(n) and want to prove S(n + 1), with n >= j0. Express S(n + 1) by substituting n + 1 for n in the statement S(n).

5. Prove S(n + 1) under the assumptions mentioned in (4). You are free to use any or all of the statements of the inductive hypothesis.

6. Conclude that S(n) is true for all n >= i0 (but not necessarily for smaller n).

Example; (p. 41, Ex. 2.3.1)

Sigma(from i=1 to n) of i = n(n + 1) / 2
  (Sigma = Oversized sigma, summation)

1. Statement S(n): Sigma(from i=1 to n) of i = n(n + 1) / 2 for any integer n >= 1.

2. Basis case: n = 1.

3. Sigma(from i=1 to n) of i = 1 * (1 + 1) / 2 = 2 / 2 = 1

4. S(n + 1) = (n + 1)((n + 1) + 1) / 2 = (n + 1)(n + 2) / 2
     = (n^2 + 3n + 2) / 2

5. Sigma(from i=1 to n+1) of i = Sigma(from i=1 to n) of i + n + 1.
                               = n(n + 1) / 2 + (n + 1)
							     (we are writing Sigma(i->n) of i as S(n))
							   = (n^2 + n) / 2 + (2 * (n + 1)) / 2
							   = (n^2 + n + 2n + 2) / 2
							   = (n^2 + 3n + 2) / 2 = S(n + 1) as in (4)

6. Therefore, we conclude that S(n) is true for n >= 1.

p. 52

A loop invariant (or inductive assertion) is a statement S that is true each time we enter a particular point in the loop. This statement, S, is then proved by induction on a parameter that measures how many times we have gone around the loop.

p. 57

Loop invariants for while-loops

p. 59

Recursive (or inductive) definitions: one or more classes of closely related objects or facts are defined in terms of the objects themselves. The definition must not be meaningless, nor paradoxical.

A recursive definition involves:

1. One or more basis rules, in which simple objects are defined

2. One or more inductive rules, whereby larger objects are defined in terms of smaller ones in the collection.

p. 60

Example: the factorial function

p. 64

Example: Balanced parentheses

p. 69

Recursive functions may be direct or indirect (only a second, third, or other function calls the original one)

p. 70

Example: factorial function in C

p. 72

Backward induction (selection sort where we swap the smallest element with the first one, and recursively sort the remainder)

p. 74

Divide-and-Conquer (definition)

p. 75

Merge Sort: a recursive, divide-and-conquer algorithm

p. 77

merge(lst1, lst2) function

p. 79

split(lst) function

p. 81

mergeSort(lst) function

p. 83

Recursive makeList() function

p. 85

Proving properties of recursive programs
Factorial and Linked list

p. 91

Benchmarking definition

p. 92

Profiling definition: determining where a program is spending its time

Statement counter: counts the number of times a statement is executed on a given set of inputs

90-10 rule: 90% of the running time is spent in 10% of the code

p. 97

Big-oh notation (definition)

p. 98

Template for big-oh proofs

p. 101

Template for proofs that a big-oh relationship is false

p. 103

Common running times

O(1)        constant
O(log n)    logarithmic
O(n)        linear
O(n log n)  n log n
O(n^2)      quadratic
O(n^3)      cubic
O(2^n)      exponential

p. 106

Logarithms in running times

log_2(n) is the number of times we have to divide by 2 to get down to 1

p. 108

Incommensurate functions are those that are not big-oh of each other.

p. 109

Analyzing the running time of a program

p. 116

Recursive rule for bounding running time

p. 120

Determine running time by climbing the structure tree (recursively)

p. 129

Program analysis in a nutshell

p. 132

Analyzing recursive functions: a recurrence relation relates the running time of a function F, T_F(n), to functions T_G(k) of other functions G in the program with argument sizes k.

p. 142

Inductions that skip some values: showing a T(n) using powers of 2 also shows it is true for all n, because T(n) does not decrease as n increases.

p. 145

Generalized form for simplest type of recurrence:

Basis: T(1) = a
Induction: T(n) = T(n-1) + g(n)

Division into two subproblems:

Basis: T(1) = a
Induction: T(n) = 2T(n/2) + g(n) for n = a power of 2 and greater than 1

p. 151

Summary of Solutions to common recurrence relations: O(n^(k+1)), O(c^n), O(n^log_d(c)), O(n^k), O(n^k log n)

p. 154

A function that takes time O(n^k) and calls itself with input of size n-1 takes time O(n^(k+1))

A function calling itself twice with recursion going on for log_2(n) levels (like merge sort) has a running time O(n log n) times the work done at each call, plus O(n) times the work done at the basis.

A function calling itself twice with recursion going on for n levels (like a Fibonacci program) has a running time exponential in n.

p. 156

Paradigm counting (combinatorics) problems:

Counting assignments: how many ways can we paint a row of n houses, each in any of k colors?

Counting permutations: how many different orderings of n distinct items are there?

Counting ordered selections: how many ways can we pick k things out of n and arranging the k things in order? Paradigm: counting the number of ways different horses can win, place (come in second), and show (come in third) in a race.

Counting the combinations of m things out of n: the selection of m from n distinct objects, without regard to the order. Paradigm: counting the number of possible poker hands.

Counting permutations with some identical items. Paradigm: counting the number of anagrams of a word that may have some letters appearing more than once.

Counting the number of ways objects, some of which may be identical, can be distributed among bins. Paradigm: counting the number of ways of distributing fruits to children.

p. 158

Counting assignments: The number of ways to assign any one of k values to each of n items is k^n (proved by induction)

p. 160

Permutation: an ordering of n distinct items in a line (where order matters)

p. 163

Formula for permutations: the number of permutations of n objects is n! 

Why a general-purpose sorting algorithm must be proportional to n log n: progressively divide the set of possible orders into those where the first and second elements are sorted, and those where they are not.

p. 166

Special-purpose linear-time sorting algorithm for inputs where they are distinct integers chosen in a given range

p. 167

Let Pi(n) be the number of permutations of n items. A generalized function Pi(n, m) is defined as the number of ways we can select m items from n, where order matters for the selected items, but not for the unselected items.

Pi(n) is Pi(n, n).

By deduction, Pi(n, m) = n(n-1)(n-2)...(n-m+1) = n! / (n-m)!

p. 171

Selecting m items out of n without regard to order is expressed as the total number of permutations Pi(n, m) divided by the number of different orders the m items can take (m!).

Recursively get the number n Choose m

Basis: nC0 = 1

Induction: if 0 < m < n, then nCm = (n-1)Cm + (n-1)C(m-1)

i) Not pick the first element, and pick m things from the remaining n-1 elements: (n-1)Cm

ii) Pick the first element and select m-1 things from the remaining n-1 elements: (n-1)C(m-1)

p. 179

Permutations with repeated items: If there are n items divided into k groups of sizes i_1, i_2, ..., i_k, then the number of different distinguishable orders of the n items is n!/ Product of i_j! for j from 1 to k

That is, divide n! by each of i_k!. If an item is unique, i_k! is 1 and has no effect.

p. 181

Distribution of objects to bins

A trick that works when distributing identical objects to several bins is to construct a string with a letter representing an item, and * representing a partition between bins. Then, we can use n Choose m to get the number of ways the items can be distributed.

Example: 4 apples distributed to 3 children:

Two * partitions are needed, so we have a string of 4 A's and 2 *'s.

The number of ways to select 4 A's out of the 6 positions is 6 Choose 4 = 15

In general, with n objects and m bins, a string's length will be n+m-1. The number of distributions is (n+m-1) Choose n

p. 182

Distributing distinguishable objects

For each class i of the items, use a character a_i.

Use m-1 *'s to represent boundaries between the m bins. Note that the *'s can be considered as a class of its own, that is, a collection of identical characters "*".

The total number of such strings is (n+m-1)! / (m-1)!(Product of i_j! for j from 1 to k)

p. 183

Comparison of Counting Problems

Must     Order      Identical
Use All  Important  Objects?
 N        N          N         Poker hands
 N        Y          N         Painting houses (with replacement),
                               Horse race (without)
 Y        N          Y         Apples to children
 Y        Y          N         Sorting
 Y        Y          Y         Anagrams

p. 184

Combining counting rules:

1. Express a count as a sequence of choices
2. Express a count as a difference of counts (exclude a certain class of arrangements)
3. Express a count as a sum of counts for subcases

p. 192

For any event E in a probability space P, the complement event E_bar is the set of points of P that are not in event E.

Prob(E) + Prob(E_bar) = 1

or

Prob(E_bar) = 1 - Prob(E)

p. 193

Conditional probability: if E and F are two events in a probability space, the conditional probability of F given E, written as Prob(F/E), is the sum of the probabilities of the points in both E and F divided by the sum of probabilities of the points in E.

p. 194

With independent experiments, Prob(F/E) = Prob(F).

Dealing two cards without replacement: Event E is that the first is an Ace, and F is that the second card is an Ace. The number of points in E is 4 * 51 = 204, for one of the four aces and the remaining 51 cards. Prob(E) = 204/2652 = 1/13.

For F, the number of points is 51 * 4. The fact that the first card is theoretically dealt first is irrelevant. Like E, Prob(F) = 204/2652 = 1/13.

There are 12 points (out of the 204) in E where the second position is an Ace. The first position can be an Ace of any of the 4 suits, and in the second position, the remaining 3 different choices = 12 choices.

So, Prob(F/E) = 12/204 = 1/17. Intuitively, given an Ace in the first position, the probability of getting another Ace is 3/51 = 1/17

p. 197

A distributive law for probabilities

By dividing the probability space of n points into regions, R_1, R_2, ..., R_k, we can write Prob(E) as Sum of (e_i/r_i)(r_i/n) for i from 1 to k, where e_i is the number of points in E that lie in region R_i, and r_i is the total number of points in R_i.

p. 199

portion of explanation: If there are three numbers out of the possible six showing, the probability is 1/2 that one of them is 1. The number of possibilities is 6 * 5 * 4 = 120

(complement event) There are five ways of picking the first number, four ways for the second, and three for the last. 5 * 4 * 3 = 60, 1 - 60/120 = 1/2

(direct way) Let the first number be 1. Then, there are 5 ways to pick the second number, and 4 ways to pick the third number = 20 ways. Repeat for letting the second number be 1, and the third number being 1. = 3 * 20 = 60/120 = 1/2.

If two numbers are showing, there are 90 points.

(direct way) Let the first and second numbers be 1. Then, there are 5 ways to pick the third number.

Let the first and third numbers be 1. Again, there are 5 ways.

Let the second and third numbers be 1. There are 5 ways.

So far, 15 ways.

Let the first number be 1 (and be the only occurrence of 1). There are 5 ways to pick the second and third numbers (these must be the same number).

Repeat for letting the second and third numbers be 1. Total = 3 * 5 = 15

The overall total is 30 ways, and 30/90 = 1/3.

p. 200

A product rule for independent experiments

The probability of a sequence of outcomes is the product of the probabilities of each outcome by itself.

Prob(E) = Sum of (1/k)Prob(E/R_i) for i from 1 to k

The probability of E is the average over all regions of the probability of E given that we are in that region.

p. 202

Bayes' Rule

Suppose E is an event partitioned into k regions R_1, R_2, ..., R_k.

Then Prob(R_j/E) = (Prob(R_j)Prob(E/R_j)) / (Sum of Prob(R_i)Prob(E/R_i) for i from 1 to k)

p. 206

Probability of the OR of two events

Rule of sums: Let G be the event that either E or F or both occur (at least one of E and F):
max(Prob(E), Prob(F)) <= Prob(G) <= Prob(E) + Prob(F)

The rule of sums applies also when the events are conditional on an event H.

p. 207

Probability of the AND of two events

Rule for products: Let G be the event that both E and F occur.
Prob(E) + Prob(F) - 1 <= Prob(G) <= min(Prob(E), Prob(F))

p. 208

Summary of Rules

Let E and F be events with probabilities p and q.

The probability of E-or-F (at least one of E and F) is at least max(p, q) and at most p + q (or 1 if p + q > 1)

The probability of E-and-F (both E and F) is at most min(p, q) and at least p + q - 1 (or 0 if p + q < 1)

If E and F are independent events, then the probability of E-and-F is pq

If E and F are independent events, then the probability of E-or-F is p + q - pq

p. 212

The expected value of a payoff function f, EV(f), is the sum over all points x of f(x)Prob(x).

When all points are equally likely, EV(f) is computed by summing f(x) for all x in the space, then dividing by the number of points in the space

The expected value is sometimes called the mean, and can be thought of as a "center of gravity"

p. 213

EV(f) = Sum of v * Prob(E_v) for all v, where v is a value and E_v is the set of points on which f produces value v.

In the case where points have equal probability, let n_v be the number of points in event E_v and n be the total number of points in the space. Then, EV(f) = (Sum of v * n_v for all v) / n.

p. 216

A Monte-Carlo algorithm is probabilistic; it makes a random selection at each iteration. It will either say "true", in which case the answer is guaranteed to be correct, or "I don't know", which could mean the answer is either true or false.

Given the probability p of the algorithm saying "true", the probability it will never say "true" is (1-p)^n for n iterations. This value decreases rapidly as n increases.

By repeating the algorithm a constant number of times, we conclude the answer is "false" if none of the repetitions produce "true". By adjusting the number of repetitions, we adjust the probability of incorrectly concluding "false" to be as low as we like, but it will never be 0.

p. 224

A recursive definition of trees:

Basis: A single node n is a tree. n is the root of this one-node tree.

Induction: Let r be a new node and T_1, T_2, ..., T_k be trees with roots c_1, c_2, ..., c_k. No node may appear more than once in each of the T_i's. A new tree T is formed with r and T_1, T_2, ..., T_k as follows:

Make r the root of tree T. Then add an edge from r to each of the c_1, c_2, ..., c_k roots, making each of these nodes a child of r. In other words, make r the parent of each of the roots of T_1, T_2, ..., T_k.

p. 225

A node is also its own ancestor.

Node d is a descendant of node a if and only if a is an ancestor of d.

By the above definition, a node is also a descendant of itself. A proper ancestor or descendant requires a path of length 1 or more.

The length of a path from m_1, m_2, ..., m_k has length k-1, one less than the number of nodes on the path.

p. 226

Nodes that have the same parent are called siblings.

An entire tree is a subtree of itself.

A leaf is a node that has no children. An interior node has one or more children. Every node is either a leaf or an interior node. If the tree is a single node, this node is both a root and a leaf.

The height of a node n is the length of a longest path from n to a leaf. The height of the tree is the height of the root. The depth, or level, of a node n is the length of the path from the root to n.

p. 228

A labeled tree's nodes have labels or values associated with each node. This label can be anything, from simple integers to complex arrays or other structures with multiple fields. A node's label can be changed, but its name cannot be changed.

p. 232

Array-of-pointers representation of trees

[  info                  ]
[ p0 | p1 | ... | p_bf-1 ]

The constant bf is the branching factor: the maximum number of children a node can have. Missing children are represented by a NULL pointer.

p. 233

A trie (pronounced "try") is a type of search tree. Each node except the root has an associated letter (the key may be something else). The node also has an associated value. The array-of-pointers representation is a trie.

p. 239

A simple recursion on a tree produces the preorder listing of the node labels of the tree. The process is: take an action A_0 on node n. Then, call itself on the first child, c_1, of n. In this recursive call, "explore" the subtree rooted at c_1. When this recursive call returns, do some other action, A_1. Then call the function on the second child of n, and so on.

The effect of a preorder listing is to print (only the first time a node is visited) as if we circumnavigated the tree counterclockwise.

p. 251

A template for structural induction

1. Specify the statement S(T) to be proved, where T is a tree
2. Prove the basis, that S(T) is true whenever T is a tree with a single node.
3. Set up the inductive step by letting T be a tree with root r and k >= 1 subtrees, T_1, T_2, ..., T_k. State that you assume the inductive hypothesis: S(T_i) is true for each of the subtrees.
4. Prove that S(T) is true under the assumptions of step 3.

p. 256

The scheme for recursions on binary trees is

{
  action A_0
  recursive call on left subtree
  action A_1
  recursive call on right subtree
  action A_2
}

p. 259

Binary search tree

p. 261

An Abstract Data Type (ADT) is a collection of operations, such as insert, delete, and lookup, that may be performed on a set of objects of a certain kind. This concept is also called a class, or a module.

An ADT can have more than one abstract implementation. For example, the binary search tree is a good way to implement the dictionary ADT. Each abstract implementation can, in turn, be implemented by several data structures.

p. 264

Deleting an element from a binary search tree

p. 272

Partially ordered trees

p. 280

Heapsort

p. 289

A sublist is a contiguous portion of a list.

A subsequence of L is a list formed by striking out zero or more elements of L. The elements of the subsequence must remain in the same order of L, but need not be consecutive in L. e (epsilon, the empty list) and L itself are always sublists and subsequences of L.

p. 293

Linked-list data structure

p. 299

Doubly linked lists

p. 303

Lookup with sentinels (a method to speed up a search) 

p. 306

Stacks: a LIFO (last-in first-out) abstract data type 

p. 318

Queues: a FIFO (first-in first-out) abstract data type

p. 320

Circular array 

p. 321

Longest common subsequence (LCS) example: say we have two lists consisting of lines from two separate files with a small number of changes between them. An LCS represents those lines that have not been changed.

A subsequence is formed from a list by deleting any number of elements, while keeping the remaining elements in order. The elements do not need to be contiguous.

p. 324

Recovering an LCS from a two-dimensional table giving the length of the LCS

p. 330

CPC (Characters Per Cell)

p. 338

Basic definitions of sets

The empty set is a set, and not an atom.

Defining a set of elements belonging to S for having a property P is called abstraction.

p. 339

A multiset may have repeated elements, but still have no order associated with its elements.

p. 341

Russell's paradox: Is set S a member of itself?

p. 344

Commutative, associative, and distributive laws of union and intersection

p. 345

Associative law of union and difference

Distributive law of difference over union

p. 347

S is a proper subset of T if S is a subset of T and there is at least one element of T that is also not in S.

p. 349

The power set of S, written P(S) or 2^S, is the set of subsets of S.

p. 357

Characteristic-vector implementation of sets

p. 361

Hash table data structure

p. 366

Relations and Functions

A set of elements, each of which is a tuple of the same arity (say, k), is called a relation of arity k.

p. 367

Cartesian product (A X B)

p. 390

Partial orders and total orders

p. 391

Equivalence relations

p. 392

Equivalence classes

p. 393

Closures of relations

p. 399

Cardinality of sets, aleph-zero (cardinality of integers)

The set of real numbers belongs to another equivalence class, called the "continuum".

p. 433

Natural join: a join of two relations R and S where (commonly) the attributes equated have the same name, and in addition, R and S have no other attribute names in common.

p. 459

Implementing graphs

Adjacency Lists

Adjacency Matrices

p. 468

An algorithm for computing the connected components

p. 478

Minimal Spanning Trees

In this context, the "tree" is unrooted and unordered (it is just an undirected graph with no simple cycles)

The tree is "minimal" when the sum of the edge labels (integers or reals) is as small as possible.

p. 479

Kruskal's algorithm is a greedy algorithm that produces a minimal spanning tree. Often, the overall effect of locally optimal decisions is not globally optimum. However, In the case of Kruskal's algorithm, the greedy approach is optimal.

p. 484

Depth-first search

To avoid infinite recursion, we mark nodes as we visit them.

p. 502

Dijkstra's algorithm for finding shortest paths

p. 514

Floyd's algorithm

p. 516

Warshall's algorithm

p. 522

A complete graph has an edge between every pair of distinct nodes. When the graph is undirected, there are n(n - 1)/2 edges.

For a complete directed graph, there are n^2 arcs.

p. 533

A bounce filter smoothes a sequence of 0's and 1's by regarding a single digit surrounded by the other as "noise."

p. 539

Nondeterministic automata

p. 547

The subset construction for creating a deterministic automaton out of a nondeterministic one.

p. 556

Regular expressions

p. 560

Kleene closure

p. 566

The backslash (\) is an escape character.

p. 572

Automata cannot count, so it is not possible for one to recognize all and only the strings of balanced parentheses.

